# 能力分类模块



## 1.功能描述

​	从职位要求信息(jobinfo)中提取句子，并将这些句子分为专业技能，个人技能，工具使用这3类的分类模型。

## 2.流程概述

**简单来说**:

![流程](D:\project\NLP\pic\流程.png)

**使用到的文件说明**：

+ stopwords.txt，停用词和分词，用于帮助清洗句子中不需要的部分

+ addwords.txt，给jieba词库增加的词汇

+ words_id.txt，模型训练时得到的词汇，每个模型和其训练时得到得words_id绑定，不要随意更改该文件。

  ​						##words_id的数量类似于模型当时训练时特征维数，若words_id更改导致维数和训练时不

  ​							一致，会导致模型无法使用。##

+ font.xlsx，数据库中的前端jobinfo，用作参考

+ doneLabel 模型训练时所使用的数据



## 3.使用包

jieba 0.22
numpy 1.14.2
pandas  0.25.0
sklearn 0.21    **##!如果你sklearn大于0.21，你需要单独安装joblib库来导入模型!##**

## 4.模块说明

![模块](D:\project\NLP\pic\模块.png)

### 4.1JobinfoSpliter

![JobinfoSpliter](D:\project\NLP\pic\JobinfoSpliter.png)

提供jobinfo分裂成句，句子变为词的方法

```
Constructor:
                    JobinfoSpliter(jobinfo,stopwords,addwords)
                    
                    jobinfo   DataFrame
                              分类所使用大文本
                    stopwords 停用词txt文件 一行一个词
                    addwords  增加词txt文件 一行一个词
                   
                    
Attributes:
                    jobinfo DataFrame
                            需要进行分类的jobinfo
                    sen     DataFrame
                            jobinfo分裂出来的句子
                    words   DataFrame
                            句子分裂后提取的词
                    stopwords str 
                              stopwords的txt文件地址
                    addwords  str 
                              addwords 的txt文件地址
Functions:
                    sen_split() 将jobinfo分成多个句子
                    Parameters: None
            	    Returns: DataFrame
                    		 self.jobinfo分裂后的句子
                    		 
                    sen2words() 将句子分成多个单词
                    Parameters: None
           		    Returns: DataFrame
                    		 self.sen分裂出来的词
                    		 
                    get_words() 调用sen_split(),sen2words()，直接获得分割为词的Dataframe       
                    Parameters: None
            	    Returns: DataFrame
                     		分割成词的结果
```

### 4.2JobinfoClassifier

![JobinfoClassifier](D:\project\NLP\pic\JobinfoClassifier.png)

jobinfo预处理+句子分类

```
Constructor:
                    JobClassifier(model,jobinfo,stopwords,addwords,words_id)
                    
                    model     .model结尾文件
                              sklearn训练完成的模型
                    jobinfo   DataFrame
                              分类所使用大文本
                    stopwords 停用词txt文件 一行一个词
                    addwords  增加词txt文件 一行一个词
                    words_id  词向量id文件  每一行为 Word-id(如 前端-1)
                   
                    
Attributes:
                    model   sklearn.svm.classes.SVC
                            导入的模型
                    words_id str 
                             词id的txt文件地址
                    jobinfo DataFrame
                            需要进行分类的jobinfo
                    sen     DataFrame
                            jobinfo分裂出来的句子
                    words   DataFrame
                            句子分裂后提取的词
                    stopwords str 
                              stopwords的txt文件地址
                    addwords  str 
                              addwords的txt文件地址
                    ids     dict
                            词id字典 key:词，value:id
                    vec     list
                            词向量
                    result  DataFrame
                            模型分类的结果，一共3列，由[句子,分割后的词，分类]组成。
                            分别对应self.sen,self.words,分类结果
        
Functions:
                    sen_split() 将jobinfo分成多个句子
                    Parameters: None
            	    Returns: DataFrame
                    		 self.jobinfo分裂后的句子
                    		 
                    sen2words() 将句子分成多个单词
                    Parameters: None
           		    Returns: DataFrame
                    		 self.sen分裂出来的词
                    		 
                    word2vec()  将单词化为词向量
                    Parameters: None
                    Returns: list
                             self.vec 词向量
                             
                    load_words_id() 读取词向量的id文件
                    Parameters: None
                    Returns: dict
                             self.ids key:词 values:id
                             
                    predict()       预测输入的文本的类别
                    Parameters: None
                    Returns: DataFrame
                             模型分类的结果，一共3列，由[句子,分割后的词，分类]组成。
                             分别对应self.sen,self.words,分类结果
                             
                    get_words_frequency() 获得词分类后,每一个类别中不同词汇的出现频率
                    Parameters: None
                    Returns: list
                             list中包含3个DataFrame，第一个DataFrame代表被分类为1(专业能力)的词的出现频统						   计,后面2个DataFrame类似。
```

### 4.3JobinfoTrainer

![JobinfoTrainer](D:\project\NLP\pic\JobinfoTrainer.png)

训练模型

```
Constructor:
                    JobinfoTrainer(stopwords,addwords,df)
                    
                    stopwords 停用词txt文件 一行一个词
                    addwords  增加词txt文件 一行一个词
                    df        DataFrame
                              default = None
                              模型训练用数据
                   
                    
Attributes:
                    model   SVC
                            训练后的模型
                    df      DataFrame
                            模型训练用数据
                    stopwords str 
                              stopwords的txt文件地址
                    addwords  str 
                              addwords的txt文件地址
                    ids     dict
                            模型训练学习到的词  key:词，value:id
                    X_train Series
                            模型训练集
                    X_test  Series
                            模型测试集
                    y_train DataFrame
                            模型训练集类别
                    y_test  DataFrame
                            模型测试集类别
                    words_id str
                             学习到的词id文件保存地址    
                    v_X_train list
                              转换为词向量矩阵的训练集，list每个元素为array(词向量)
                    v_X_test list
                             转换为词向量矩阵的测试集，list每个元素为array(词向量)
        
Functions:
                    transform() 将训练数据的标签进行转换,如果标签为1,2,3形式则不使用该方法
                    Parameters: int
                       		    i
                    Returns: int
                             转换后的标签
                             
                    read_excels_from_dir() 读取文件夹内的所有excel，并将其合并为一个DataFrame。
             							**文件夹内应该只有excel文件**  
                    Parameters: str
                                 f_dir 文件夹地址
                                 bool
                                 tran 是否要使用transform()
                    Returns: DataFrame
                             合并excel后的DataFrame
                              
                    sen2words() 将句子化为单词
                    Parameters: None
            	    Returns: DataFrame
                     		 转变成词后的训练集
                     		 
                    word2vec()  将单词化为词向量
                    Parameters: DataFrame
                                df 需要转换为词向量的训练集
                                dict
                                word_id 模型训练学习到的词  key:词，value:id
                   Returns: DataFrame
                            转变成词向量后的训练集
                            
                    get_words_id() 获得训练数据的词id，并把它写入txt文件
                    Parameters: str
                        	    f_id 词id文件保存的地址
            	    Returns: DataFrame
                     	     转变成词后的训练集
                    
                    fit() 训练模型
                    Parameters: int 
                                cv 交叉验证的次数 
                                str
                                f_id 词id文件位置                  
                    Returns: SVC
                             训练完后的模型
                             
                    get_score() 查看模型的训练效果
                    Parameters: array-like
                       		    y_test 测试集标签
                                array-like
                                y_pred 模型预测的结果
                                int 
                                cv 交叉验证的次数  
           		   Returns: None
                    
                    dump_model() 将模型导出
                    Parameters: str
                        		f_model 模型导出的文件名          
            	    Returns: None
```

